{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp0hEkuCiu5ALb9XzMmHOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LosDatalovers/LosDatalovers/blob/main/segundo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LosDatalovers/LosDatalovers.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cI56Vk3pGaA",
        "outputId": "eb417029-3d40-4f38-ed94-c60e0d7206b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LosDatalovers' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "W2rEBfauo6CQ",
        "outputId": "8189460c-4683-49f8-ffe3-1c7c77905c98"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Ciencia de Datos\\\\Dataset_Estudiantes.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-56f4e46b248f>\u001b[0m in \u001b[0;36m<cell line: 191>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleerLimpiar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhorasEstudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;31m#graficos(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-56f4e46b248f>\u001b[0m in \u001b[0;36mleerLimpiar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'Ciencia de Datos\\Dataset_Estudiantes.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcolumnas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Edad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Genero'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Puntaje matematicas'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Puntaje Lengua'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Asistencia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumnas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Ciencia de Datos\\\\Dataset_Estudiantes.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "def leerLimpiar():\n",
        "    url = r'Ciencia de Datos\\Dataset_Estudiantes.csv'\n",
        "    columnas = ['Edad','Genero','Puntaje matematicas','Puntaje Lengua','Asistencia']\n",
        "    df = pd.read_csv(url, sep=';', usecols=columnas)\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "def horasEstudio(df):\n",
        "    # Rango de horas de estudio para los puntajes más altos\n",
        "    max = 16\n",
        "    min = 2\n",
        "\n",
        "    # Normalizar los puntajes de matemáticas entre 0 y 1\n",
        "    df['Puntaje Normalizado'] = (df['Puntaje matematicas'] - df['Puntaje matematicas'].min()) / (df['Puntaje matematicas'].max() - df['Puntaje matematicas'].min())\n",
        "\n",
        "    # Generar las horas de estudio basadas en el puntaje normalizado\n",
        "    df['Horas de estudio semanal'] = df['Puntaje Normalizado'] * (max - min) + min\n",
        "\n",
        "    # Añadir un factor de aleatoriedad para simular variabilidad\n",
        "    df['Horas de estudio semanal'] += np.random.normal(0, 1.5, len(df))\n",
        "\n",
        "    # Redondear a una hora cercana\n",
        "    df['Horas de estudio semanal'] = df['Horas de estudio semanal'].clip(lower=min, upper=max).round()\n",
        "\n",
        "    # Eliminar columna de puntaje normalizado si no es necesaria\n",
        "    df.drop(columns=['Puntaje Normalizado'], inplace=True)\n",
        "\n",
        "    df.to_csv('Ciencia de Datos/Dataset_Estudiantes.csv', sep=';', index=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "def graficos(df):\n",
        "    #Comparando según genero\n",
        "    promedio = df.groupby('Genero')[['Puntaje matematicas', 'Puntaje Lengua']].mean()\n",
        "    posiciones = np.arange(len(promedio))\n",
        "    ancho = 0.4\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(posiciones - ancho/2, promedio['Puntaje matematicas'], ancho, label='Matemáticas', color='skyblue')\n",
        "    plt.bar(posiciones + ancho/2, promedio['Puntaje Lengua'], ancho, label='Lengua', color='lightcoral')\n",
        "    plt.xlabel('Género')\n",
        "    plt.ylabel('Puntaje Promedio')\n",
        "    plt.title('Puntaje Promedio en Matemáticas y Lengua por Género')\n",
        "    plt.xticks(posiciones, promedio.index)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Gráfico de dispersión\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(df['Puntaje matematicas'], df['Puntaje Lengua'], alpha=0.6, color='purple')\n",
        "    plt.xlim(df['Puntaje matematicas'].min() - 3, df['Puntaje matematicas'].max() + 3)\n",
        "    plt.ylim(df['Puntaje Lengua'].min() - 3, df['Puntaje Lengua'].max() + 3)\n",
        "    plt.plot([0, 103], [0, 103], color='red', linestyle='--', linewidth=2, label=\"Igual Puntaje\")\n",
        "    plt.title(\"Relación entre Matemáticas y Lengua\")\n",
        "    plt.xlabel(\"Puntaje en Matemáticas\")\n",
        "    plt.ylabel(\"Puntaje en Lengua\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Grafico de Estudio\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(df['Puntaje matematicas'], df['Horas de estudio semanal'], alpha=0.6, color='blue')\n",
        "    plt.title(\"Relación entre Calificación en Matemáticas y Horas de Estudio\")\n",
        "    plt.xlabel(\"Puntaje en Matemáticas\")\n",
        "    plt.ylabel(\"Horas de Estudio Semanal\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def asimetria(df):\n",
        "    if df[['Puntaje matematicas', 'Asistencia', 'Edad', 'Horas de estudio semanal']].isnull().any().any():\n",
        "        print(\"Existen valores nulos en las variables. Asegúrate de tratarlos antes de calcular la asimetría.\")\n",
        "        return\n",
        "\n",
        "    # Asimetría de Puntaje matemáticas por Género\n",
        "    matematicas = df.groupby('Genero')['Puntaje matematicas'].skew()\n",
        "    asistencia = df['Asistencia'].skew()\n",
        "    edad = df['Edad'].skew()\n",
        "    estudio = df['Horas de estudio semanal'].skew()\n",
        "\n",
        "    print(\"Asimetría del Puntaje en Matemáticas por Género:\")\n",
        "    for genero, asimetria_valor in matematicas.items():\n",
        "        print(f\"{genero}: {asimetria_valor:.2f}\")\n",
        "\n",
        "    print(f\"\\nAsimetría de la Asistencia: {asistencia:.2f}\")\n",
        "    print(f\"Asimetría de la Edad: {edad:.2f}\")\n",
        "    print(f\"Asimetría de las Horas de estudio semanal: {estudio:.2f}\")\n",
        "\n",
        "def regresionMultiple(df):\n",
        "    X = df[['Edad', 'Asistencia', 'Horas de estudio semanal']]\n",
        "    Y = df['Puntaje matematicas']\n",
        "\n",
        "    # Escalar las variables\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Dividir en entrenamiento y prueba (80% - 20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Crear el modelo de regresión lineal múltiple\n",
        "    modelo = LinearRegression()\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Realizar predicciones\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    print(\"Coeficientes:\", modelo.coef_)\n",
        "    print(\"Intersección (intercept):\", modelo.intercept_)\n",
        "    print(\"\\nEvaluación del modelo:\")\n",
        "    print(f\"R^2 (Coeficiente de determinación): {modelo.score(X_test, y_test):.2f}\")\n",
        "    print(f\"Error Absoluto Medio (MAE): {mean_absolute_error(y_test, y_pred):.2f}\")\n",
        "    print(f\"Error Cuadrático Medio (MSE): {mean_squared_error(y_test, y_pred):.2f}\")\n",
        "    print(f\"Raíz del Error Cuadrático Medio (RMSE): {mean_squared_error(y_test, y_pred, squared=False):.2f}\")\n",
        "\n",
        "def correlacion(df):\n",
        "\n",
        "    df['Genero'] = df['Genero'].map({'Masculino': 1, 'Femenino': 0})\n",
        "    correlaciones = df.corr()\n",
        "    correlacion_puntaje_matematicas = correlaciones['Puntaje matematicas'].sort_values(ascending=False)\n",
        "    print(\"Variables con mejor correlación con el Puntaje en Matemáticas:\")\n",
        "    print(correlacion_puntaje_matematicas)\n",
        "\n",
        "def sinergias(df):\n",
        "    # Excluir 'Genero' de la lista de columnas a imputar\n",
        "    columnas_imputar = ['Horas de estudio semanal', 'Edad', 'Asistencia']\n",
        "\n",
        "    # Imputación de valores faltantes\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    df[columnas_imputar] = imputer.fit_transform(df[columnas_imputar])\n",
        "\n",
        "    # Eliminar 'Genero' de las variables predictoras\n",
        "    X = df[['Horas de estudio semanal', 'Edad', 'Asistencia']]\n",
        "    y = df['Puntaje matematicas']\n",
        "\n",
        "    # Dividir en datos de entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Crear y entrenar el modelo\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Mostrar los resultados del modelo\n",
        "    print(\"R^2 en entrenamiento:\", modelo.score(X_train, y_train))\n",
        "    print(\"R^2 en prueba:\", modelo.score(X_test, y_test))\n",
        "\n",
        "def regrecionLogistica(df):\n",
        "    # Crear columna binaria para aprobación: 1 si aprueba 0 si no\n",
        "    df['Aprobado'] = df['Puntaje matematicas'].apply(lambda x: 1 if x >= 70 else 0)\n",
        "\n",
        "    # Variables predictoras y variable objetivo\n",
        "    X = df[['Edad', 'Asistencia', 'Horas de estudio semanal']]\n",
        "    y = df['Aprobado']\n",
        "\n",
        "    # Escalar las variables\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # División de datos en entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Crear el modelo de regresión logística\n",
        "    modelo = LogisticRegression()\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Realizar predicciones\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    print(\"Exactitud (Accuracy):\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "df = leerLimpiar()\n",
        "df = horasEstudio(df)\n",
        "#graficos(df)\n",
        "#asimetria(df)\n",
        "#correlacion(df) #Compruebo que variables son las mas optimas para el analisis de datos\n",
        "#sinergias(df)\n",
        "#regresionMultiple(df)\n",
        "regrecionLogistica(df)\n",
        "\n",
        "\n",
        "#print(\"\\n Registros completos\")\n",
        "#print(df)\n",
        "\n",
        "# print(\"\\n Descripcion\")\n",
        "# print(df.describe().round(2))"
      ]
    }
  ]
}